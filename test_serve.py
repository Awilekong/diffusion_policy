#!/usr/bin/env python3
"""
æµ‹è¯• serve_diffusion_policy.py è„šæœ¬
éªŒè¯ checkpoint åŠ è½½å’Œæ¨ç†åŠŸèƒ½
"""

import sys
import os
import numpy as np
import torch

# æ·»åŠ è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..', 'web_policy'))

from serve_diffusion_policy import DiffusionPolicyWrapper


def test_checkpoint_loading(ckpt_path: str, device: str = 'cuda'):
    """æµ‹è¯• checkpoint åŠ è½½"""
    print("=" * 70)
    print("ğŸ§ª æµ‹è¯• 1: Checkpoint åŠ è½½")
    print("=" * 70)
    
    try:
        policy = DiffusionPolicyWrapper(
            ckpt_path=ckpt_path,
            device=device
        )
        print("\nâœ… Checkpoint åŠ è½½æˆåŠŸï¼")
        return policy
    except Exception as e:
        print(f"\nâŒ Checkpoint åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def test_metadata(policy: DiffusionPolicyWrapper):
    """æµ‹è¯•å…ƒæ•°æ®"""
    print("\n" + "=" * 70)
    print("ğŸ§ª æµ‹è¯• 2: Policy å…ƒæ•°æ®")
    print("=" * 70)
    
    metadata = policy.metadata
    print("\nğŸ“Š å…ƒæ•°æ®ä¿¡æ¯:")
    for key, value in metadata.items():
        if key == 'shape_meta':
            print(f"   {key}:")
            print(f"      obs keys: {list(value['obs'].keys())}")
            print(f"      action keys: {list(value['action'].keys())}")
        else:
            print(f"   {key}: {value}")
    
    return metadata


def test_dummy_inference(policy: DiffusionPolicyWrapper):
    """æµ‹è¯•è™šæ‹Ÿæ•°æ®æ¨ç†"""
    print("\n" + "=" * 70)
    print("ğŸ§ª æµ‹è¯• 3: è™šæ‹Ÿæ•°æ®æ¨ç†")
    print("=" * 70)
    
    shape_meta = policy.shape_meta
    n_obs_steps = policy.n_obs_steps
    
    # åˆ›å»ºè™šæ‹Ÿè§‚æµ‹æ•°æ®
    print(f"\nğŸ”¨ åˆ›å»ºè™šæ‹Ÿè§‚æµ‹æ•°æ® (n_obs_steps={n_obs_steps})...")
    dummy_obs = {}
    
    for key, attr in shape_meta['obs'].items():
        obs_type = attr.get('type', 'low_dim')
        shape = attr.get('shape')
        
        if obs_type == 'rgb':
            # å›¾åƒ: shape_meta ä¸­æ˜¯ (C, H, W)ï¼Œè¾“å…¥éœ€è¦ (n_obs_steps, H, W, C)
            c, h, w = shape
            dummy_obs[key] = np.random.randint(
                0, 255, 
                size=(n_obs_steps, h, w, c), 
                dtype=np.uint8
            )
            print(f"   {key} (å›¾åƒ): shape={dummy_obs[key].shape}, dtype={dummy_obs[key].dtype}")
        
        elif obs_type == 'low_dim':
            # ä½ç»´æ•°æ®: (n_obs_steps, *shape)
            dummy_obs[key] = np.random.randn(n_obs_steps, *shape).astype(np.float32)
            print(f"   {key} (ä½ç»´): shape={dummy_obs[key].shape}, dtype={dummy_obs[key].dtype}")
    
    # æ‰§è¡Œæ¨ç†
    print(f"\nğŸ”® æ‰§è¡Œæ¨ç†...")
    try:
        result = policy.infer(dummy_obs)
        
        print(f"\nâœ… æ¨ç†æˆåŠŸï¼")
        print(f"\nğŸ“¤ è¾“å‡ºç»“æœ:")
        for key, value in result.items():
            print(f"   {key}: shape={value.shape}, dtype={value.dtype}")
            if value.size <= 20:  # å¦‚æœæ•°æ®é‡ä¸å¤§ï¼Œæ‰“å°ä¸€ä¸‹
                print(f"      å€¼: {value.flatten()}")
            else:
                print(f"      å‰5ä¸ªå€¼: {value.flatten()[:5]}")
                print(f"      å5ä¸ªå€¼: {value.flatten()[-5:]}")
        
        return result
    
    except Exception as e:
        print(f"\nâŒ æ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def test_multiple_inferences(policy: DiffusionPolicyWrapper, n_runs: int = 5):
    """æµ‹è¯•å¤šæ¬¡æ¨ç†"""
    print("\n" + "=" * 70)
    print(f"ğŸ§ª æµ‹è¯• 4: å¤šæ¬¡æ¨ç† (n={n_runs})")
    print("=" * 70)
    
    shape_meta = policy.shape_meta
    n_obs_steps = policy.n_obs_steps
    
    # åˆ›å»ºè™šæ‹Ÿè§‚æµ‹æ•°æ®
    dummy_obs = {}
    for key, attr in shape_meta['obs'].items():
        obs_type = attr.get('type', 'low_dim')
        shape = attr.get('shape')
        
        if obs_type == 'rgb':
            c, h, w = shape
            dummy_obs[key] = np.random.randint(
                0, 255, 
                size=(n_obs_steps, h, w, c), 
                dtype=np.uint8
            )
        elif obs_type == 'low_dim':
            dummy_obs[key] = np.random.randn(n_obs_steps, *shape).astype(np.float32)
    
    # å¤šæ¬¡æ¨ç†
    print(f"\nğŸ”„ æ‰§è¡Œ {n_runs} æ¬¡æ¨ç†...")
    import time
    
    inference_times = []
    actions_list = []
    
    for i in range(n_runs):
        start_time = time.time()
        result = policy.infer(dummy_obs)
        end_time = time.time()
        
        inference_time = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        inference_times.append(inference_time)
        actions_list.append(result['actions'])
        
        print(f"   Run {i+1}: {inference_time:.2f} ms")
    
    # ç»Ÿè®¡
    print(f"\nğŸ“Š æ¨ç†æ€§èƒ½ç»Ÿè®¡:")
    print(f"   å¹³å‡æ—¶é—´: {np.mean(inference_times):.2f} ms")
    print(f"   æœ€å¿«: {np.min(inference_times):.2f} ms")
    print(f"   æœ€æ…¢: {np.max(inference_times):.2f} ms")
    print(f"   æ ‡å‡†å·®: {np.std(inference_times):.2f} ms")
    
    # æ£€æŸ¥è¾“å‡ºæ˜¯å¦ç¨³å®šï¼ˆç›¸åŒè¾“å…¥åº”è¯¥äº§ç”Ÿç›¸åŒè¾“å‡ºï¼‰
    print(f"\nğŸ” æ£€æŸ¥è¾“å‡ºç¡®å®šæ€§:")
    if n_runs >= 2:
        diff = np.abs(actions_list[0] - actions_list[1])
        max_diff = np.max(diff)
        mean_diff = np.mean(diff)
        print(f"   å‰ä¸¤æ¬¡æ¨ç†å·®å¼‚ - æœ€å¤§: {max_diff:.6f}, å¹³å‡: {mean_diff:.6f}")
        if max_diff < 1e-5:
            print(f"   âœ… è¾“å‡ºç¡®å®šæ€§è‰¯å¥½ï¼ˆå·®å¼‚ < 1e-5ï¼‰")
        else:
            print(f"   âš ï¸ è¾“å‡ºå­˜åœ¨å·®å¼‚ï¼ˆå¯èƒ½ç”±äºéšæœºé‡‡æ ·ï¼‰")


def test_reset(policy: DiffusionPolicyWrapper):
    """æµ‹è¯• reset åŠŸèƒ½"""
    print("\n" + "=" * 70)
    print("ğŸ§ª æµ‹è¯• 5: Reset åŠŸèƒ½")
    print("=" * 70)
    
    try:
        policy.reset()
        print("\nâœ… Reset æˆåŠŸï¼")
    except Exception as e:
        print(f"\nâŒ Reset å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def main():
    # Checkpoint è·¯å¾„
    ckpt_path = "/home/zpw/ws_zpw/megvii/IL/diffusion_policy/data/outputs/2025.11.23/23.27.07_train_diffusion_unet_franka_image_franka_peg_in_hole_image/checkpoints/latest.ckpt"
    
    print("\nğŸ¯ æµ‹è¯•ç›®æ ‡:")
    print(f"   Checkpoint: {ckpt_path}")
    print(f"   è®¾å¤‡: {'cuda' if torch.cuda.is_available() else 'cpu'}")
    
    # æµ‹è¯• 1: åŠ è½½ checkpoint
    policy = test_checkpoint_loading(ckpt_path)
    if policy is None:
        print("\nâŒ æµ‹è¯•ç»ˆæ­¢ï¼šæ— æ³•åŠ è½½ checkpoint")
        return
    
    # æµ‹è¯• 2: å…ƒæ•°æ®
    metadata = test_metadata(policy)
    
    # æµ‹è¯• 3: è™šæ‹Ÿæ•°æ®æ¨ç†
    result = test_dummy_inference(policy)
    if result is None:
        print("\nâš ï¸ è·³è¿‡åç»­æµ‹è¯•")
        return
    
    # æµ‹è¯• 4: å¤šæ¬¡æ¨ç†
    test_multiple_inferences(policy, n_runs=5)
    
    # æµ‹è¯• 5: Reset
    test_reset(policy)
    
    # æ€»ç»“
    print("\n" + "=" * 70)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("=" * 70)
    print("\nâœ… ä¸‹ä¸€æ­¥:")
    print("   1. å¯åŠ¨æœåŠ¡å™¨: python serve_diffusion_policy.py -i <checkpoint_path>")
    print("   2. æµ‹è¯•å®¢æˆ·ç«¯: python test_remote_inference.py")
    print()


if __name__ == '__main__':
    main()
