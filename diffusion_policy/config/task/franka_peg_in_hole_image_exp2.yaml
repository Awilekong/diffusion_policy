name: franka_peg_in_hole_image_exp2

# 图像配置 - 对应你的 480x640 分辨率
image_shape: [3, 480, 640]  # C, H, W

# 数据集路径
dataset_path: /home/zpw/ws_zpw/zpw/data/zarr_dataset/peg_in_hole_zarr

shape_meta: &shape_meta
  # acceptable types: rgb, low_dim
  obs:
    # 相机配置 - 根据需要选择使用哪些相机
    camera_0:  # main_realsense
      shape: ${task.image_shape}
      type: rgb
    camera_1:  # handeye_realsense
      shape: ${task.image_shape}
      type: rgb
    camera_2:  # side_realsense
      shape: ${task.image_shape}
      type: rgb

    # 末端位姿状态 (7维: xyz + rotation_vector + gripper)
    # 可选 dims 参数用于选择特定维度:
    #   dims: "xyz"     → 只用位置 (3维)
    #   dims: "xyzrpw"  → 位置+旋转 (6维)
    #   dims: "xyzrpwg" → 完整 (7维)
    #   dims: "xyzg"    → 位置+夹爪 (4维)
    # 维度映射: x=0, y=1, z=2, r=3(roll), p=4(pitch), w=5(yaw), g=6(gripper)
    robot_eef_pose:
      shape: [7]
      type: low_dim
      # dims: "xyz"  # 取消注释以只使用位置

  # 动作空间 (7维: 6维末端位姿 + 1维夹爪)
  # 同样支持 dims 参数
  action:
    shape: [7]
    # dims: "xyz"  # 取消注释以只输出位置动作

# 如果需要运行真机推理，配置 env_runner
# env_runner:
#   _target_: diffusion_policy.env_runner.franka_image_runner.FrankaImageRunner

dataset:
  _target_: diffusion_policy.dataset.real_pusht_image_dataset.RealPushTImageDataset
  shape_meta: *shape_meta
  dataset_path: ${task.dataset_path}
  horizon: ${horizon}
  pad_before: ${eval:'${n_obs_steps}-1+${n_latency_steps}'}
  pad_after: ${eval:'${n_action_steps}-1'}
  n_obs_steps: ${dataset_obs_steps}
  n_latency_steps: ${n_latency_steps}
  use_cache: True
  seed: 42
  val_ratio: 0.02  # 2% 作为验证集
  max_train_episodes: 50  # 实验2: 只使用50条数据
  delta_action: False  # False 表示使用绝对位姿作为动作
