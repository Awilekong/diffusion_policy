#!/usr/bin/env python3
"""
å¯¹æ¯”æ¨ç†æ—¥å¿—å’Œè®­ç»ƒæ•°æ®

ç”¨äºè¯Šæ–­è®­ç»ƒå’Œæ¨ç†æ—¶çš„ obs å¤„ç†æ˜¯å¦å¯¹é½

Usage:
    # å¯¹æ¯”æ¨ç†æ—¥å¿—ä¸è®­ç»ƒæ•°æ®
    python compare_debug.py \
        --inference-log debug_logs/20231201_120000_step_0000.npz \
        --train-dataset /path/to/dataset.zarr \
        --episode 0 --step 10
    
    # åªæŸ¥çœ‹æ¨ç†æ—¥å¿—
    python compare_debug.py \
        --inference-log debug_logs/20231201_120000_step_0000.npz
"""

import click
import numpy as np
from pathlib import Path
import zarr
import matplotlib.pyplot as plt
from matplotlib.gridspec import GridSpec


def print_section(title):
    """æ‰“å°åˆ†èŠ‚æ ‡é¢˜"""
    print(f"\n{'='*80}")
    print(f"  {title}")
    print(f"{'='*80}")


def print_data_stats(name, data, indent=2):
    """æ‰“å°æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
    prefix = " " * indent
    if isinstance(data, dict):
        print(f"{prefix}{name}: (dict with {len(data)} keys)")
        for key, value in data.items():
            if isinstance(value, np.ndarray):
                print(f"{prefix}  {key}: shape={value.shape}, dtype={value.dtype}")
            else:
                print(f"{prefix}  {key}: {type(value).__name__}")
    elif isinstance(data, np.ndarray):
        print(f"{prefix}{name}: shape={data.shape}, dtype={data.dtype}")
    else:
        print(f"{prefix}{name}: {type(data).__name__} = {data}")


def visualize_image_processing_pipeline(inference_data, train_data=None, output_dir=None):
    """
    å¯è§†åŒ–å›¾åƒå¤„ç†æµæ°´çº¿çš„æ¯ä¸€æ­¥
    
    å¯¹æ¯”æ¨ç†å’Œè®­ç»ƒæ—¶çš„å›¾åƒå¤„ç†è¿‡ç¨‹ï¼š
    1. input_obs_raw: åŸå§‹è¾“å…¥å›¾åƒ
    2. env_obs: å†å²é˜Ÿåˆ—ç»„è£…å
    3. obs_dict_np: get_real_obs_dict è¾“å‡ºï¼ˆresize + å½’ä¸€åŒ–ï¼‰
    4. obs_dict_tensor: æ¨¡å‹è¾“å…¥
    """
    print_section("ğŸ“¸ å¯è§†åŒ–å›¾åƒå¤„ç†æµæ°´çº¿")
    
    if output_dir is None:
        output_dir = Path('debug_comparison')
    else:
        output_dir = Path(output_dir)
    output_dir.mkdir(exist_ok=True)
    
    # æå–æ¨ç†æ•°æ®
    input_raw = inference_data.get('input_obs_raw', {})
    env_obs = inference_data.get('env_obs', {})
    obs_dict_np = inference_data.get('obs_dict_np', {})
    obs_dict_tensor = inference_data.get('obs_dict_tensor', {})
    
    # æ‰¾åˆ°æ‰€æœ‰ç›¸æœº
    camera_keys = [k for k in env_obs.keys() if 'camera' in k]
    
    if not camera_keys:
        print("   âš ï¸  æœªæ‰¾åˆ°å›¾åƒæ•°æ®")
        return
    
    print(f"   æ‰¾åˆ° {len(camera_keys)} ä¸ªç›¸æœº: {camera_keys}")
    
    for cam_key in camera_keys:
        print(f"\n   ğŸ¥ å¤„ç† {cam_key}:")
        
        # æå–å„é˜¶æ®µæ•°æ®
        # 1. åŸå§‹è¾“å…¥ (å¦‚æœæœ‰)
        raw_img = None
        for obs_key in input_raw.keys():
            if 'image' in obs_key:
                # æ‰¾åˆ°å¯¹åº”çš„ç›¸æœº
                if cam_key == 'camera_0' and obs_key == 'observation/image':
                    raw_img = input_raw[obs_key]
                    break
                elif cam_key == 'camera_1' and obs_key == 'observation/image_1':
                    raw_img = input_raw[obs_key]
                    break
                elif cam_key == 'camera_2' and obs_key == 'observation/image_2':
                    raw_img = input_raw[obs_key]
                    break
        
        # 2. å†å²é˜Ÿåˆ— (n_obs_steps, H, W, C)
        env_imgs = env_obs.get(cam_key)
        if env_imgs is None:
            print(f"      âš ï¸  åœ¨ env_obs ä¸­æœªæ‰¾åˆ° {cam_key}")
            continue
        
        n_obs_steps = env_imgs.shape[0]
        
        # 3. get_real_obs_dict è¾“å‡º (n_obs_steps, C, H, W)
        processed_imgs = obs_dict_np.get(cam_key)
        if processed_imgs is None:
            print(f"      âš ï¸  åœ¨ obs_dict_np ä¸­æœªæ‰¾åˆ° {cam_key}")
            continue
        
        # 4. æ¨¡å‹è¾“å…¥ (1, n_obs_steps, C, H, W)
        tensor_imgs = obs_dict_tensor.get(cam_key)
        if tensor_imgs is not None:
            tensor_imgs = tensor_imgs[0]  # å»æ‰ batch ç»´åº¦
        
        # åˆ›å»ºå¯è§†åŒ–
        # æ¯ä¸€è¡Œæ˜¾ç¤ºä¸€ä¸ªå†å²å¸§ï¼Œæ¯ä¸€åˆ—æ˜¾ç¤ºä¸€ä¸ªå¤„ç†é˜¶æ®µ
        n_stages = 4 if raw_img is not None else 3
        fig = plt.figure(figsize=(5*n_stages, 4*n_obs_steps))
        gs = GridSpec(n_obs_steps, n_stages, figure=fig)
        
        for t in range(n_obs_steps):
            col = 0
            
            # é˜¶æ®µ1: åŸå§‹è¾“å…¥ï¼ˆå¦‚æœæ˜¯ç¬¬ä¸€å¸§ä¸”æœ‰åŸå§‹æ•°æ®ï¼‰
            if raw_img is not None:
                ax = fig.add_subplot(gs[t, col])
                if t == 0:
                    img_show = raw_img
                    if img_show.dtype == np.uint8:
                        ax.imshow(img_show)
                    else:
                        ax.imshow(np.clip(img_show, 0, 1))
                    ax.set_title(f'1. åŸå§‹è¾“å…¥ (t={t})\nshape={img_show.shape}\ndtype={img_show.dtype}')
                else:
                    ax.text(0.5, 0.5, f'å†å²å¸§ (t={t})\nä½¿ç”¨ç¬¬0å¸§å¡«å……', 
                           ha='center', va='center', transform=ax.transAxes)
                    ax.set_title(f'1. åŸå§‹è¾“å…¥ (t={t})')
                ax.axis('off')
                col += 1
            
            # é˜¶æ®µ2: å†å²é˜Ÿåˆ— (n_obs_steps, H, W, C)
            ax = fig.add_subplot(gs[t, col])
            img_show = env_imgs[t]  # (H, W, C)
            if img_show.dtype == np.uint8:
                ax.imshow(img_show)
            else:
                ax.imshow(np.clip(img_show, 0, 1))
            ax.set_title(f'2. å†å²é˜Ÿåˆ— (t={t})\nshape={img_show.shape}\ndtype={img_show.dtype}')
            ax.axis('off')
            col += 1
            
            # é˜¶æ®µ3: get_real_obs_dict è¾“å‡º (n_obs_steps, C, H, W)
            ax = fig.add_subplot(gs[t, col])
            img_show = processed_imgs[t]  # (C, H, W)
            img_show = np.transpose(img_show, (1, 2, 0))  # -> (H, W, C)
            ax.imshow(np.clip(img_show, 0, 1))
            ax.set_title(f'3. get_real_obs_dict (t={t})\nå¤„ç†: resize+å½’ä¸€åŒ–\nshape={processed_imgs[t].shape}\nrange=[{processed_imgs[t].min():.2f}, {processed_imgs[t].max():.2f}]')
            ax.axis('off')
            col += 1
            
            # é˜¶æ®µ4: æ¨¡å‹è¾“å…¥ (n_obs_steps, C, H, W)
            if tensor_imgs is not None:
                ax = fig.add_subplot(gs[t, col])
                img_show = tensor_imgs[t]  # (C, H, W)
                img_show = np.transpose(img_show, (1, 2, 0))  # -> (H, W, C)
                ax.imshow(np.clip(img_show, 0, 1))
                ax.set_title(f'4. æ¨¡å‹è¾“å…¥ (t={t})\næ·»åŠ batchç»´åº¦\nshape={tensor_imgs[t].shape}\nrange=[{tensor_imgs[t].min():.2f}, {tensor_imgs[t].max():.2f}]')
                ax.axis('off')
        
        plt.suptitle(f'æ¨ç†å›¾åƒå¤„ç†æµæ°´çº¿: {cam_key}\nä»å·¦åˆ°å³å±•ç¤ºå„å¤„ç†é˜¶æ®µï¼Œä»ä¸Šåˆ°ä¸‹å±•ç¤ºå†å²å¸§', 
                    fontsize=14, y=0.995)
        plt.tight_layout()
        
        output_file = output_dir / f'{cam_key}_pipeline.png'
        plt.savefig(output_file, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"      âœ… å·²ä¿å­˜: {output_file}")
    
    print(f"\n   ğŸ“ æ‰€æœ‰å¯è§†åŒ–å›¾ç‰‡å·²ä¿å­˜åˆ°: {output_dir}")


def compare_arrays(name, arr1, arr2, rtol=1e-5, atol=1e-8):
    """å¯¹æ¯”ä¸¤ä¸ªæ•°ç»„æ˜¯å¦æ¥è¿‘"""
    print(f"\n  ğŸ” å¯¹æ¯” {name}:")
    print(f"     æ¨ç†: shape={arr1.shape}, dtype={arr1.dtype}")
    print(f"     è®­ç»ƒ: shape={arr2.shape}, dtype={arr2.dtype}")
    
    if arr1.shape != arr2.shape:
        print(f"     âŒ Shape ä¸åŒ¹é…!")
        return False
    
    if arr1.dtype != arr2.dtype:
        print(f"     âš ï¸  Dtype ä¸åŒï¼Œå°è¯•è½¬æ¢...")
        arr2 = arr2.astype(arr1.dtype)
    
    # ç»Ÿè®¡ä¿¡æ¯å¯¹æ¯”
    print(f"     æ¨ç†: range=[{arr1.min():.4f}, {arr1.max():.4f}], mean={arr1.mean():.4f}, std={arr1.std():.4f}")
    print(f"     è®­ç»ƒ: range=[{arr2.min():.4f}, {arr2.max():.4f}], mean={arr2.mean():.4f}, std={arr2.std():.4f}")
    
    # æ•°å€¼å¯¹æ¯”
    if np.allclose(arr1, arr2, rtol=rtol, atol=atol):
        print(f"     âœ… æ•°å€¼å®Œå…¨å¯¹é½ (rtol={rtol}, atol={atol})")
        return True
    else:
        diff = np.abs(arr1 - arr2)
        max_diff = diff.max()
        mean_diff = diff.mean()
        print(f"     âŒ æ•°å€¼ä¸å¯¹é½: max_diff={max_diff:.6f}, mean_diff={mean_diff:.6f}")
        
        # æ‰¾åˆ°æœ€å¤§å·®å¼‚çš„ä½ç½®
        max_idx = np.unravel_index(diff.argmax(), diff.shape)
        print(f"     æœ€å¤§å·®å¼‚ä½ç½® {max_idx}: æ¨ç†={arr1[max_idx]:.6f}, è®­ç»ƒ={arr2[max_idx]:.6f}")
        return False


def load_inference_log(log_path):
    """åŠ è½½æ¨ç†æ—¥å¿—"""
    print_section("ğŸ“¥ åŠ è½½æ¨ç†æ—¥å¿—")
    print(f"   æ–‡ä»¶: {log_path}")
    
    data = np.load(log_path, allow_pickle=True)
    
    # æå–æ•°æ®
    result = {}
    for key in data.files:
        if key == 'metadata':
            result[key] = data[key].item()  # dict
        else:
            result[key] = data[key].item() if data[key].shape == () else data[key]
    
    print(f"   âœ… åŠ è½½æˆåŠŸï¼ŒåŒ…å« {len(result)} ä¸ªå­—æ®µ:")
    for key in result.keys():
        print(f"      - {key}")
    
    return result


def load_train_sample(dataset_path, episode_idx, step_idx):
    """ä»è®­ç»ƒæ•°æ®é›†åŠ è½½ä¸€ä¸ªæ ·æœ¬"""
    print_section("ğŸ“¥ åŠ è½½è®­ç»ƒæ•°æ®")
    print(f"   æ•°æ®é›†: {dataset_path}")
    print(f"   Episode: {episode_idx}, Step: {step_idx}")
    
    root = zarr.open(dataset_path, 'r')
    
    # è·å–æ ·æœ¬æ•°æ®
    sample = {}
    
    # è¯»å–æ•°æ®é”®
    data_group = root['data']
    print(f"   å¯ç”¨æ•°æ®é”®: {list(data_group.keys())}")
    
    for key in data_group.keys():
        data = data_group[key]
        # ä» episode çš„ç‰¹å®š step æå–æ•°æ®
        if hasattr(data, 'shape') and len(data.shape) > 0:
            # å‡è®¾æ•°æ®æ ¼å¼æ˜¯ (episode_len, ...) æŒ‰ episode æ‹¼æ¥
            # éœ€è¦æ ¹æ®ä½ çš„æ•°æ®é›†æ ¼å¼è°ƒæ•´
            sample[key] = data[episode_idx, step_idx]
    
    print(f"   âœ… åŠ è½½æˆåŠŸ")
    return sample


@click.command()
@click.option('--inference-log', '-i', required=True, 
              help='æ¨ç†æ—¥å¿—æ–‡ä»¶ (.npz)')
@click.option('--train-dataset', '-t', default=None,
              help='è®­ç»ƒæ•°æ®é›†è·¯å¾„ (.zarr)')
@click.option('--episode', '-e', default=0, type=int,
              help='è®­ç»ƒæ•°æ®é›†çš„ episode ç´¢å¼•')
@click.option('--step', '-s', default=0, type=int,
              help='è®­ç»ƒæ•°æ®é›†çš„ step ç´¢å¼•')
@click.option('--output-dir', '-o', default='debug_comparison',
              help='å¯è§†åŒ–è¾“å‡ºç›®å½•')
def main(inference_log, train_dataset, episode, step, output_dir):
    """å¯¹æ¯”æ¨ç†æ—¥å¿—å’Œè®­ç»ƒæ•°æ®"""
    
    print("="*80)
    print("  Diffusion Policy è®­ç»ƒæ¨ç†æ•°æ®å¯¹æ¯”å·¥å…·")
    print("="*80)
    
    # 1. åŠ è½½æ¨ç†æ—¥å¿—
    inference_data = load_inference_log(inference_log)
    
    # 2. æ‰“å°æ¨ç†æ•°æ®æµ
    print_section("ğŸ“Š æ¨ç†æ•°æ®æµ")
    
    print("\n1ï¸âƒ£  input_obs_raw (åŸå§‹è¾“å…¥):")
    if 'input_obs_raw' in inference_data:
        print_data_stats('input_obs_raw', inference_data['input_obs_raw'])
    
    print("\n2ï¸âƒ£  env_obs (å†å²é˜Ÿåˆ—ç»„è£…å):")
    if 'env_obs' in inference_data:
        print_data_stats('env_obs', inference_data['env_obs'])
    
    print("\n3ï¸âƒ£  obs_dict_np (get_real_obs_dict è¾“å‡º):")
    if 'obs_dict_np' in inference_data:
        print_data_stats('obs_dict_np', inference_data['obs_dict_np'])
    
    print("\n4ï¸âƒ£  obs_dict_tensor (æ¨¡å‹è¾“å…¥):")
    if 'obs_dict_tensor' in inference_data:
        print_data_stats('obs_dict_tensor', inference_data['obs_dict_tensor'])
    
    print("\n5ï¸âƒ£  action (æ¨¡å‹è¾“å‡º):")
    if 'action' in inference_data:
        print_data_stats('action', inference_data['action'])
    
    print("\nğŸ“ Metadata:")
    if 'metadata' in inference_data:
        metadata = inference_data['metadata']
        for key, value in metadata.items():
            if key != 'shape_meta':  # shape_meta å¤ªé•¿
                print(f"   {key}: {value}")
    
    # 2. å¯è§†åŒ–å›¾åƒå¤„ç†æµæ°´çº¿
    visualize_image_processing_pipeline(inference_data, output_dir=output_dir)
    
    # 3. å¦‚æœæä¾›äº†è®­ç»ƒæ•°æ®é›†ï¼Œè¿›è¡Œå¯¹æ¯”
    if train_dataset:
        try:
            train_sample = load_train_sample(train_dataset, episode, step)
            
            print_section("ğŸ”„ è®­ç»ƒæ•°æ®å¯¹æ¯”")
            print("æ³¨æ„ï¼šéœ€è¦æ ¹æ®ä½ çš„æ•°æ®é›†æ ¼å¼è°ƒæ•´å¯¹æ¯”é€»è¾‘")
            print("ä»¥ä¸‹æ˜¯ç¤ºä¾‹å¯¹æ¯”ï¼Œå¯èƒ½éœ€è¦ä¿®æ”¹:")
            
            # ç¤ºä¾‹ï¼šå¯¹æ¯” obs_dict_np çš„æŸäº›å­—æ®µ
            # å…·ä½“å¯¹æ¯”é€»è¾‘éœ€è¦æ ¹æ®ä½ çš„æ•°æ®é›†æ ¼å¼è°ƒæ•´
            print("\næç¤ºï¼šè¯·æ ¹æ®å®é™…æ•°æ®é›†ç»“æ„ä¿®æ”¹æ­¤è„šæœ¬çš„å¯¹æ¯”é€»è¾‘")
            
        except Exception as e:
            print(f"\nâš ï¸  åŠ è½½è®­ç»ƒæ•°æ®å¤±è´¥: {e}")
            print("   æç¤ºï¼šè¯·æ£€æŸ¥æ•°æ®é›†è·¯å¾„å’Œæ ¼å¼")
    
    print_section("âœ… å¯¹æ¯”å®Œæˆ")
    print(f"\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print(f"   1. æŸ¥çœ‹å¯è§†åŒ–å›¾ç‰‡: {output_dir}/")
    print(f"   2. å¯¹æ¯”å„å¤„ç†é˜¶æ®µçš„å›¾åƒæ˜¯å¦ç¬¦åˆé¢„æœŸ")
    print(f"   3. æ£€æŸ¥ resizeã€å½’ä¸€åŒ–ç­‰æ“ä½œæ˜¯å¦æ­£ç¡®")
    print(f"   4. é‡ç‚¹å…³æ³¨å›¾åƒçš„åˆ†è¾¨ç‡ã€é¢œè‰²èŒƒå›´ã€å†…å®¹æ˜¯å¦æ¸…æ™°")
    print(f"   5. å¦‚æœæœ‰è®­ç»ƒæ•°æ®ï¼Œå¯ä»¥å¯¹æ¯”è®­ç»ƒå’Œæ¨ç†çš„å›¾åƒå¤„ç†æ˜¯å¦ä¸€è‡´")


if __name__ == '__main__':
    main()
